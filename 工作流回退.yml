name: Update IP and Time (BJ)

on:
  schedule:
    # GitHub 免费版限制最小间隔约 5 分钟
    - cron: '*/15 * * * *'
  workflow_dispatch:

# =========================================================
# 核心配置区域 (所有输出均为 .md 格式)
# =========================================================
env:
  # --- 1. 速度测试 (15分钟/历史) ---
  FILE_15M_IP: "15分钟内_纯IP.md"
  FILE_15M_INFO: "15分钟内_完整信息.md"
  FILE_HIST_IP: "历史最快_纯IP.md"
  FILE_HIST_INFO: "历史最快_完整信息.md"
  
  # --- 2. 新增抓取源 ---
  FILE_LATENCY: "24小时三网延迟最低统计.md"
  FILE_COLO: "CloudFlare数据中心.md"
  
  # --- 3. 日志 ---
  FILE_LOG: "运行日志.md"

# =========================================================

permissions:
  contents: write

jobs:
  fetch-and-update:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install requests beautifulsoup4

      - name: Run Script
        # 传递环境变量
        env:
          FILE_15M_IP: ${{ env.FILE_15M_IP }}
          FILE_15M_INFO: ${{ env.FILE_15M_INFO }}
          FILE_HIST_IP: ${{ env.FILE_HIST_IP }}
          FILE_HIST_INFO: ${{ env.FILE_HIST_INFO }}
          FILE_LATENCY: ${{ env.FILE_LATENCY }}
          FILE_COLO: ${{ env.FILE_COLO }}
          FILE_LOG: ${{ env.FILE_LOG }}
        run: |
          cat << 'EOF' > run_script.py
          import requests
          from bs4 import BeautifulSoup
          import re
          import os
          from datetime import datetime, timedelta, timezone

          # --- 环境变量获取 ---
          F_15M_IP = os.getenv('FILE_15M_IP', '15m_ip.md')
          F_15M_INFO = os.getenv('FILE_15M_INFO', '15m_info.md')
          F_HIST_IP = os.getenv('FILE_HIST_IP', 'hist_ip.md')
          F_HIST_INFO = os.getenv('FILE_HIST_INFO', 'hist_info.md')
          F_LATENCY = os.getenv('FILE_LATENCY', 'latency.md')
          F_COLO = os.getenv('FILE_COLO', 'colo.md')
          F_LOG = os.getenv('FILE_LOG', 'log.md')

          MAX_HISTORY_COUNT = 30
          MAX_LOG_LINES = 30
          HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

          # --- 辅助函数：Markdown 表格生成 ---
          def write_md_table(filename, headers, data_rows):
              """
              headers: list of strings ['IP', 'Speed']
              data_rows: list of lists [['1.1.1.1', '100'], ...]
              """
              with open(filename, 'w', encoding='utf-8') as f:
                  # 写入表头
                  f.write("| " + " | ".join(headers) + " |\n")
                  # 写入分割线
                  f.write("| " + " | ".join(['---'] * len(headers)) + " |\n")
                  # 写入数据
                  for row in data_rows:
                      # 确保每个单元格内容存在，转为字符串
                      row_str = [str(x) if x else " " for x in row]
                      f.write("| " + " | ".join(row_str) + " |\n")

          def write_md_codeblock(filename, ip_list):
              """将纯IP列表写入 markdown 代码块，方便全选复制"""
              with open(filename, 'w', encoding='utf-8') as f:
                  f.write("```text\n")
                  for ip in ip_list:
                      f.write(f"{ip}\n")
                  f.write("```\n")

          # --- 类定义 ---
          class IpNode:
              def __init__(self, ip, isp, speed_str, bandwidth, latency, datacenter, raw_line=None):
                  self.ip = ip
                  self.isp = isp
                  self.speed_str = speed_str
                  self.bandwidth = bandwidth
                  self.latency = latency
                  self.datacenter = datacenter
                  self.speed_int = self.extract_speed(speed_str) if speed_str else 0
                  
                  # 兼容从旧的txt历史文件读取逻辑 (虽然现在改用md，但为了健壮性保留部分逻辑)
                  if raw_line and self.speed_int == 0:
                      self.speed_int = self.extract_speed(raw_line)

              def extract_speed(self, s):
                  match = re.search(r'(\d+)', s)
                  return int(match.group(1)) if match else 0
              
              def to_md_row(self):
                  # IP 加反引号方便复制
                  return [f"`{self.ip}`", self.isp, self.speed_str, self.bandwidth, self.latency, self.datacenter]

          # --- 1. 抓取测速数据 (原逻辑) ---
          def fetch_speed_data():
              urls = [
                  ("EdgeOne", "https://www.wetest.vip/page/edgeone/address_v4.html"),
                  ("CloudFlare", "https://www.wetest.vip/page/cloudflare/address_v4.html")
              ]
              nodes = []
              print("正在抓取测速数据...")
              for name, url in urls:
                  try:
                      resp = requests.get(url, headers=HEADERS, timeout=15)
                      if resp.status_code != 200: continue
                      soup = BeautifulSoup(resp.text, 'html.parser')
                      for tr in soup.find_all('tr'):
                          tds = tr.find_all('td')
                          if len(tds) < 6: continue
                          try:
                              isp = tds[0].get_text(strip=True)
                              ip = tds[1].get_text(strip=True)
                              bw = tds[2].get_text(strip=True)
                              spd = tds[3].get_text(strip=True)
                              lat = tds[4].get_text(strip=True)
                              dc = tds[5].get_text(strip=True)
                              if ip.count('.') == 3:
                                  node = IpNode(ip, isp, spd, bw, lat, dc)
                                  if node.speed_int > 0:
                                      nodes.append(node)
                          except: continue
                  except Exception as e:
                      print(f"抓取测速错误 {name}: {e}")
              return nodes

          # --- 2. 抓取三网延迟 (新逻辑) ---
          def fetch_latency_data():
              url = "https://www.wetest.vip/page/cloudflare/total_v4.html"
              data_rows = []
              print("正在抓取三网延迟数据...")
              try:
                  resp = requests.get(url, headers=HEADERS, timeout=15)
                  if resp.status_code == 200:
                      soup = BeautifulSoup(resp.text, 'html.parser')
                      rows = soup.find_all('tr')
                      # 限制前15个 (注意: 网页可能有表头，需判断 td 数量)
                      count = 0
                      for tr in rows:
                          if count >= 15: break
                          tds = tr.find_all('td')
                          if len(tds) < 4: continue
                          
                          # 提取: IP, 移动, 联通, 电信
                          ip = tds[0].get_text(strip=True)
                          cm = tds[1].get_text(strip=True)
                          cu = tds[2].get_text(strip=True)
                          ct = tds[3].get_text(strip=True)
                          
                          # 格式化 IP 方便复制
                          data_rows.append([f"`{ip}`", cm, cu, ct])
                          count += 1
              except Exception as e:
                  print(f"抓取延迟数据出错: {e}")
              return data_rows

          # --- 3. 抓取数据中心 (新逻辑) ---
          def fetch_colo_data():
              url = "https://www.wetest.vip/page/cloudflare/colo.html"
              data_rows = []
              print("正在抓取数据中心数据...")
              try:
                  resp = requests.get(url, headers=HEADERS, timeout=15)
                  if resp.status_code == 200:
                      soup = BeautifulSoup(resp.text, 'html.parser')
                      rows = soup.find_all('tr')
                      for tr in rows:
                          tds = tr.find_all('td')
                          # 需要提取8列: 代码, 名称, 国家, 洲, 移动IP, 联通IP, 电信IP, 更新时间
                          if len(tds) < 8: continue
                          
                          code = tds[0].get_text(strip=True)
                          name = tds[1].get_text(strip=True)
                          country = tds[2].get_text(strip=True)
                          continent = tds[3].get_text(strip=True)
                          mob_ip = tds[4].get_text(strip=True)
                          uni_ip = tds[5].get_text(strip=True)
                          tel_ip = tds[6].get_text(strip=True)
                          time_val = tds[7].get_text(strip=True)
                          
                          # 对三个 IP 进行格式化
                          data_rows.append([
                              code, name, country, continent,
                              f"`{mob_ip}`", f"`{uni_ip}`", f"`{tel_ip}`",
                              time_val
                          ])
              except Exception as e:
                  print(f"抓取数据中心出错: {e}")
              return data_rows

          # --- 历史数据加载 (解析 Markdown 表格) ---
          def load_history_nodes_from_md():
              nodes = []
              if not os.path.exists(F_HIST_INFO):
                  return nodes
              try:
                  with open(F_HIST_INFO, 'r', encoding='utf-8') as f:
                      lines = f.readlines()
                      # 跳过前两行 (表头和分割线)
                      for line in lines:
                          if "|" not in line or "---" in line or "IP" in line: continue
                          
                          # 分割并去除空白 | IP | 线路 | ... |
                          parts = [p.strip() for p in line.split('|') if p.strip()]
                          if len(parts) >= 6:
                              # parts[0] 是 `1.1.1.1`，需要去除反引号
                              raw_ip = parts[0].replace('`', '')
                              isp = parts[1]
                              speed = parts[2]
                              bw = parts[3]
                              lat = parts[4]
                              dc = parts[5]
                              
                              nodes.append(IpNode(raw_ip, isp, speed, bw, lat, dc))
              except Exception as e:
                  print(f"读取历史文件警告: {e}")
              return nodes

          def update_log(msg):
              lines = []
              if os.path.exists(F_LOG):
                  try:
                      with open(F_LOG, 'r', encoding='utf-8') as f:
                          lines = f.readlines()
                  except: pass
              
              # 插入新日志 (Markdown列表格式)
              lines.insert(0, f"- {msg}\n")
              lines = lines[:MAX_LOG_LINES]
              
              with open(F_LOG, 'w', encoding='utf-8') as f:
                  f.writelines(lines)

          # ================= 主程序 =================
          if __name__ == "__main__":
              utc_now = datetime.now(timezone.utc)
              bj_time = utc_now + timedelta(hours=8)
              time_str = bj_time.strftime('%Y-%m-%d %H:%M:%S')

              # ----------------------------------------
              # 任务1: 处理 15分钟测速 & 历史排名
              # ----------------------------------------
              current_nodes = fetch_speed_data()
              current_nodes.sort(key=lambda x: x.speed_int, reverse=True)

              # 输出 15分钟 完整信息 (表格)
              header_speed = ["IP", "线路", "速度", "带宽", "延迟", "数据中心"]
              data_15m = [n.to_md_row() for n in current_nodes]
              write_md_table(F_15M_INFO, header_speed, data_15m)
              
              # 输出 15分钟 纯IP (代码块)
              write_md_codeblock(F_15M_IP, [n.ip for n in current_nodes])

              # 处理历史排名
              history_nodes = load_history_nodes_from_md()
              ip_map = {}
              # 合并历史与当前 (保留更快的)
              for n in history_nodes:
                  if n.ip not in ip_map or n.speed_int > ip_map[n.ip].speed_int:
                      ip_map[n.ip] = n
              for n in current_nodes:
                  if n.ip not in ip_map or n.speed_int > ip_map[n.ip].speed_int:
                      ip_map[n.ip] = n
              
              merged = list(ip_map.values())
              merged.sort(key=lambda x: x.speed_int, reverse=True)
              top_30 = merged[:MAX_HISTORY_COUNT]

              # 输出 历史 完整信息 (表格)
              data_hist = [n.to_md_row() for n in top_30]
              write_md_table(F_HIST_INFO, header_speed, data_hist)

              # 输出 历史 纯IP (代码块)
              write_md_codeblock(F_HIST_IP, [n.ip for n in top_30])

              # ----------------------------------------
              # 任务2: 处理 三网延迟统计
              # ----------------------------------------
              latency_rows = fetch_latency_data()
              header_latency = ["IP地址", "移动延迟", "联通延迟", "电信延迟"]
              write_md_table(F_LATENCY, header_latency, latency_rows)

              # ----------------------------------------
              # 任务3: 处理 数据中心
              # ----------------------------------------
              colo_rows = fetch_colo_data()
              header_colo = ["代码", "地区", "国家", "洲", "移动IP", "联通IP", "电信IP", "更新时间"]
              write_md_table(F_COLO, header_colo, colo_rows)

              # ----------------------------------------
              # 任务4: 写日志
              # ----------------------------------------
              log_msg = ""
              if current_nodes:
                  best = current_nodes[0]
                  log_msg = f"**{time_str}** 更新成功 | 测速IP数: {len(current_nodes)} | 延迟统计: {len(latency_rows)} | 数据中心: {len(colo_rows)} | 本次最快: `{best.ip}` ({best.speed_str})"
              else:
                  log_msg = f"**{time_str}** 更新部分完成 (未获取到测速IP) | 延迟统计: {len(latency_rows)} | 数据中心: {len(colo_rows)}"
              
              update_log(log_msg)
              print("所有任务处理完成")

          EOF

          python run_script.py

      - name: Commit and Push Changes
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          
          # 添加所有生成的文件
          git add "$FILE_15M_IP" "$FILE_15M_INFO" "$FILE_HIST_IP" "$FILE_HIST_INFO" "$FILE_LATENCY" "$FILE_COLO" "$FILE_LOG"
          
          if git diff --staged --quiet; then
            echo "没有变更需要提交"
          else
            CURRENT_TIME=$(date "+%Y-%m-%d %H:%M:%S")
            git commit -m "Update All IPs (MD Format): $CURRENT_TIME"
            git push
            echo "推送成功"
          fi
